{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeeb8f7",
   "metadata": {},
   "source": [
    "# Image scraper for Google Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1283ef",
   "metadata": {},
   "source": [
    "This script is an image scraper for Google images to collect data of both authentic and bootleg plushies. <br>\n",
    "Since the site only allows 20 images per scraping, I would have to execute the script multiple times with different search queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e554c0",
   "metadata": {},
   "source": [
    "Import all necessary models to make the image scraper work and save all the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bde05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from builtins import open, bytes\n",
    "import uuid\n",
    "import time\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f2424",
   "metadata": {},
   "source": [
    "The scraper is into a function so it can be executed multiple times by just referencing it. The function accepts the search query with the parameter 'query' <br>\n",
    "1. A variable with the URL is made to pass the search query in it. To pass information from the site to my PC, a header is made to send a request to the URL and get the response which is parsed HTML data \n",
    "2. The script finds every image element in the HTML that include a source, and gets the URLs of these\n",
    "3. A folder where the images go is refenced in a variable. If the folder does not exist, it will be created first\n",
    "4. Using a 'for loop', the images are downloaded from their source URLs and saved in the aforementioned folder. The images are retrieved and saved by creating the file first and copying the source data from the images in it as binary data, which is used for non-text files\n",
    "<br> <br> \n",
    "The images are named according to the character and authenticity. To prevent the images from overridding eachother, a randomized string of characters is added at the end of a filename. The script also checks if the source URL starts with 'http' to download the images. If not the case, the protocol indicator is added at the start of the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5df2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(query):\n",
    "    url = 'https://www.google.com/search?q=' + query + '&source=lnms&tbm=isch'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    protocol_indicator = \"https://images.google.com\"\n",
    "\n",
    "    images = soup.find_all('img')\n",
    "    image_urls = [image['src'] for image in images]\n",
    "\n",
    "    # Create a directory to store the images\n",
    "    folder_name = 'mmm'\n",
    "    if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "    # Download the images and save them to the directory\n",
    "    for i, url in enumerate(image_urls):\n",
    "        \n",
    "        random_string = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
    "        filename = random_string\n",
    "\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = protocol_indicator + url\n",
    "            \n",
    "        response = requests.get(url, stream=True)\n",
    "        file_name = os.path.join(f\"{folder_name}/cinnamoroll_authentic_{filename}.jpg\")\n",
    "        with open(file_name, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "        del response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c8564",
   "metadata": {},
   "source": [
    "The function is called with the search query in the parameter, to which the first 20 images of it are downloaded in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea5815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_images(\"cinnamoroll plush official\")\n",
    "scrape_images(\"cinnamoroll plush sanrio\")\n",
    "scrape_images(\"cinnamoroll plush\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
