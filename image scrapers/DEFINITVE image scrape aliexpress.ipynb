{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8ab63f",
   "metadata": {},
   "source": [
    "# Image scraper for AliExpress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d578ed",
   "metadata": {},
   "source": [
    "Import all necessary models to make the image scraper work and save all the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7562d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from builtins import open, bytes\n",
    "import time\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0acf17",
   "metadata": {},
   "source": [
    "The scraper is into a function so it can be executed multiple times by just referencing it. The function accept a URL with the parameter 'url' <br>\n",
    "1. A response to the URL is made, to which the page HTML source is parsed in test\n",
    "2. The script finds every image element in the HTML that include a source and aria-label, and gets the URLs of these. The inclusion of the aria-label is to exclude other non-relevant images on the page that don't have the element\n",
    "3. A folder where the images go is refenced in a variable. If the folder does not exist, it will be created first\n",
    "4. Using a 'for loop', the images are downloaded from their source URLs and saved in the aforementioned folder. To avoid the possibility of overloading the server, the script pauses 3 seconds for every 10 seconds. The images are retrieved and saved by creating the file first and copying the source data from the images in it as binary data, which is used for non-text files\n",
    "<br> <br> \n",
    "The images are named according to the authenticity. To prevent the images from overridding eachother, a randomized string of characters is added at the end of a filename. The script also checks if the source URL starts with 'http' to download the images. If not the case, the protocol indicator is added at the start of the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472afc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    protocol_indicator = \"https:\"\n",
    "\n",
    "    imgs = soup.find_all(\"img\", {\"src\":True, \"aria-hidden\":True})\n",
    "\n",
    "    folder_name = 'test'\n",
    "    if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "    for i, img in enumerate (imgs):\n",
    "        if i % 10 == 0:\n",
    "            time.sleep(3)\n",
    "            \n",
    "        src = img[\"src\"]\n",
    "        \n",
    "        random_string = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
    "        filename = random_string\n",
    "        \n",
    "        if not src.startswith(\"http\"):\n",
    "            src = protocol_indicator + src\n",
    "        response = requests.get(src)\n",
    "            \n",
    "        with open(f\"{folder_name}/bootleg_{filename}.jpg\", 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8676d",
   "metadata": {},
   "source": [
    "The function is called with the URL in the parameter, to which all the images are downloaded in the folder. As there are multiple pages of listings on the site, the function would have to be called for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f09e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=7\")\n",
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=8\")\n",
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=9\")\n",
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=10\")\n",
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=11\")\n",
    "download_images(\"https://www.aliexpress.com/w/wholesale-sanrio-plushies.html?page=12\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
